{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Importing Models\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Importing other tools\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "# from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, StratifiedKFold\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import plotly.express as px\n",
    "import itertools\n",
    "from mlflow import sklearn\n",
    "import mlflow.sklearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading local functions\n",
    "from src.features.build_features import prep_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence \\m\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\m\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\m\n",
      "<ipython-input-3-7cdce46e39a1>:1: DeprecationWarning: invalid escape sequence \\m\n",
      "  data = pd.read_csv(\"C:\\mlops_plugin\\src\\data\\data.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\mlops_plugin\\src\\data\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://kubernetes.docker.internal:5000/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"Pre_Process\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,X,y = prep_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex  Embarked  Title  IsAlone  FareBand  AgeBand\n",
       "875       3    1         1      2        1         0        0\n",
       "251       3    1         0      3        0         1        2\n",
       "327       2    1         0      3        1         1        3\n",
       "512       1    0         0      1        1         2        3\n",
       "515       1    0         0      1        1         3        3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'Modeling' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"Modeling\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_params = {\n",
    "  'seed':123,\n",
    "  'folds': 10,\n",
    "  'test_size': 0.3,\n",
    "  'train_size': 0.7,\n",
    "  'n_jobs':-1,\n",
    "  'verbose':3,\n",
    "  'scoring':'f1',   \n",
    "  'Split_type': 'ShuffleSplit',\n",
    "  'warning': warnings.filterwarnings('ignore'),\n",
    "  'normalize': True\n",
    "}\n",
    "\n",
    "base_model = {\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'BaggingClassifier':BaggingClassifier(),\n",
    "    'ExtraTreesClassifier':ExtraTreesClassifier(),\n",
    "    'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "    'RandomForestClassifier':RandomForestClassifier(),\n",
    "    'GaussianProcessClassifier':gaussian_process.GaussianProcessClassifier(),\n",
    "    'LogisticRegressionCV':linear_model.LogisticRegressionCV(),\n",
    "    'PassiveAggressiveClassifier':linear_model.PassiveAggressiveClassifier(),\n",
    "    'RidgeClassifierCV':linear_model.RidgeClassifierCV(),\n",
    "    'SGDClassifier':linear_model.SGDClassifier(),\n",
    "    'Perceptron':linear_model.Perceptron(),\n",
    "    'BernoulliNB':naive_bayes.BernoulliNB(),\n",
    "    'GaussianNB':naive_bayes.GaussianNB(),\n",
    "    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "    'SVC':svm.SVC(probability=True),\n",
    "    'NuSVC':svm.NuSVC(probability=True),\n",
    "    'LinearSVC':svm.LinearSVC(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'LinearDiscriminantAnalysis':discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    'QuadraticDiscriminantAnalysis':discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    'XGBClassifier':XGBClassifier(),\n",
    "    'LGBMClassifier':LGBMClassifier()   \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModellingHelper:\n",
    "\n",
    "    def __init__(self, std_param, base_model):\n",
    "        \n",
    "        self.std_param = std_param\n",
    "        if self.std_param['Split_type'] == 'ShuffleSplit':\n",
    "          self.cross_val = model_selection.ShuffleSplit(n_splits = self.std_param['folds'], test_size = self.std_param['test_size'], train_size = self.std_param['train_size'], random_state = self.std_param['seed'] )\n",
    "\n",
    "        self.base_model = base_model\n",
    "        self.base_model_output = {}\n",
    "        self.feature_importance_df_sorted = pd.DataFrame()\n",
    "        self.important_col =[]\n",
    "\n",
    "        self.scoring = { 'accuracy' : make_scorer(metrics.accuracy_score),\n",
    "                  'precision' : make_scorer(metrics.precision_score),\n",
    "                  'recall' : make_scorer(metrics.recall_score),\n",
    "                  'f1_score' : make_scorer(metrics.f1_score),\n",
    "                  'average_precision': make_scorer(metrics.average_precision_score),\n",
    "                  'balanced_accuracy': make_scorer(metrics.balanced_accuracy_score),\n",
    "                  'hamming_loss':make_scorer(metrics.hamming_loss),\n",
    "                  'jaccard_score': make_scorer(metrics.jaccard_score),\n",
    "                  'log_loss': make_scorer(metrics.log_loss),\n",
    "                  'roc_auc_score':make_scorer(metrics.roc_auc_score),\n",
    "                  'zero_one_loss':make_scorer(metrics.zero_one_loss,normalize=False)\n",
    "                  }\n",
    "\n",
    "\n",
    "        self.scores_list = []\n",
    "        self.feature_importance = {}\n",
    "        self.FeatureImportanceAlgo = ['DecisionTreeClassifier','RandomForestClassifier','ExtraTreesClassifier','GradientBoostingClassifier','AdaBoostClassifier']\n",
    "\n",
    "    def getScoreDictionary(self, base_model_output,modelname, basemodel_scores, score_type):\n",
    "      self.base_model_output[modelname]['Time'] = basemodel_scores['fit_time'].mean()\n",
    "      self.base_model_output[modelname]['%s_accuracy' %score_type ] =  basemodel_scores['%s_accuracy' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_precision' %score_type ] =  basemodel_scores['%s_precision' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_recall' %score_type ] =  basemodel_scores['%s_recall' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_f1_score' %score_type ] =  basemodel_scores['%s_f1_score' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_average_precision' %score_type ] =  basemodel_scores['%s_average_precision' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_balanced_accuracy' %score_type ] =  basemodel_scores['%s_balanced_accuracy' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_hamming_loss' %score_type ] =  basemodel_scores['%s_hamming_loss' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_jaccard_score' %score_type ] =  basemodel_scores['%s_jaccard_score' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_log_loss' %score_type ] =  basemodel_scores['%s_log_loss' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_roc_auc_score' %score_type ] =  basemodel_scores['%s_roc_auc_score' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_zero_one_loss' %score_type ] =  basemodel_scores['%s_zero_one_loss' %score_type].mean()\n",
    "\n",
    "      return None\n",
    "\n",
    "    def ModelLoop(self,X, y, score_type=None):\n",
    "        \n",
    "      for key, eachModel in self.base_model.items():\n",
    "          with mlflow.start_run(nested=True):\n",
    "              basemodel_scores = model_selection.cross_validate(eachModel, X,y, cv  = self.cross_val,return_train_score=True,scoring=self.scoring, pre_dispatch=\"2*n_jobs\",return_estimator=True)\n",
    "              modelname = eachModel.__class__.__name__\n",
    "              self.base_model_output[modelname] = {}\n",
    "              self.getScoreDictionary(self.base_model_output,modelname, basemodel_scores, 'train')\n",
    "              self.getScoreDictionary(self.base_model_output,modelname, basemodel_scores, 'test')\n",
    "              self.scores_list.append(basemodel_scores)\n",
    "              mlflow.log_param(\"Model\", modelname)\n",
    "              mlflow.log_param(\"time\", self.base_model_output[modelname]['Time'])\n",
    "    #           mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    #           mlflow.log_metric(\"rmse\", rmse)\n",
    "    #           mlflow.log_metric(\"r2\", r2)\n",
    "              score_type_mlflow = 'test'\n",
    "              mlflow.log_metric(\"accuracy\", basemodel_scores['%s_accuracy' %score_type_mlflow].mean())\n",
    "              mlflow.log_metric(\"Precision\", basemodel_scores['%s_precision' %score_type_mlflow].mean())\n",
    "              mlflow.log_metric(\"Recall\", basemodel_scores['%s_recall' %score_type_mlflow].mean())\n",
    "              mlflow.log_metric(\"F1\", basemodel_scores['%s_f1_score' %score_type_mlflow].mean())\n",
    "#               print (basemodel_scores['estimator'])\n",
    "#               mlflow.end_run()\n",
    "    #         mlflow.sklearn.log_model(lr, \"model\")\n",
    "              model = eachModel.fit(X,y)\n",
    "              modelpath = \"C://mlops_plugin//models//model-%s%f\" % (modelname,random())\n",
    "              mlflow.sklearn.save_model(model, modelpath)\n",
    "#               flow.sklearn.log_model(model,\"model\")\n",
    "              \n",
    "              if eachModel.__class__.__name__ in self.FeatureImportanceAlgo:\n",
    "                eachModel.fit(X,y)\n",
    "                self.feature_importance[eachModel.__class__.__name__]= eachModel.feature_importances_\n",
    "            \n",
    "\n",
    "    def runBaseLineModel(self, X, y, score_type=None, auto_feature_eng = None , top_feature = None ):\n",
    "      if top_feature:\n",
    "        print (\"Building model with only %s important feature\" % top_feature)\n",
    "        #Initial Model Loop to extract top feature\n",
    "        self.ModelLoop(X, y, score_type)\n",
    "        imp_df = self.getFeatureImportance(self.getFeatureImportanceDF(X, self.feature_importance))\n",
    "        important_col = list(imp_df[:top_feature].index)\n",
    "        self.important_col = important_col\n",
    "        X = X[important_col]\n",
    "        self.ModelLoop(X, y,score_type)\n",
    "        # tracking \n",
    "\n",
    "      else:\n",
    "        print (\"Building model without any important feature\")\n",
    "        self.ModelLoop(X, y,score_type)\n",
    "\n",
    "    def getFeatureImportanceDF(self, X, feature_importance_dict, important_col=None):\n",
    "      if important_col:\n",
    "        feature_names = important_col\n",
    "        feat_imp_df = pd.DataFrame.from_dict(feature_importance_dict)\n",
    "        feat_imp_df.index = feature_names\n",
    "        return feat_imp_df\n",
    "      else:\n",
    "        feature_names = X.columns\n",
    "        feat_imp_df = pd.DataFrame.from_dict(feature_importance_dict)\n",
    "        feat_imp_df.index = feature_names\n",
    "        return feat_imp_df\n",
    "\n",
    "    def getFeatureImportance(self,feat_imp_df):\n",
    "      mms = MinMaxScaler()\n",
    "      # scaling to MinMax Scale\n",
    "      scaled_fi = pd.DataFrame(data=mms.fit_transform(feat_imp_df),columns=feat_imp_df.columns,index=feat_imp_df.index)\n",
    "      # Adding all values of importance to get single socre\n",
    "      scaled_fi['SumofImp'] = scaled_fi.sum(axis=1)\n",
    "      # print(scaled_fi.head())\n",
    "      ordered_ranking = scaled_fi.sort_values('SumofImp', ascending=False)\n",
    "      return ordered_ranking\n",
    "\n",
    "\n",
    "    def getFeatureImportanceGraph(self,ordered_feature_importance_df):\n",
    "      self.feature_importance_df_sorted.append(ordered_feature_importance_df)\n",
    "      fig, ax = plt.subplots(figsize=(10,7), dpi=80)\n",
    "      sns.barplot(data=ordered_feature_importance_df, y=ordered_feature_importance_df.index, x='SumofImp', palette='magma')\n",
    "      ax.spines['right'].set_visible(False)\n",
    "      ax.spines['top'].set_visible(False)\n",
    "      ax.spines['bottom'].set_visible(False)\n",
    "      ax.xaxis.set_visible(False)\n",
    "      ax.grid(False)\n",
    "      ax.set_title('Aggregated Feature Importances for Models');\n",
    "      return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelObject = BaseModellingHelper(basic_params,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with only 5 important feature\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-8d7d04e4d33d>\u001b[0m in \u001b[0;36mrunBaseLineModel\u001b[1;34m(self, X, y, score_type, auto_feature_eng, top_feature)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Building model with only %s important feature\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtop_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m#Initial Model Loop to extract top feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mimp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetFeatureImportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetFeatureImportanceDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mimportant_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimp_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtop_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-8d7d04e4d33d>\u001b[0m in \u001b[0;36mModelLoop\u001b[1;34m(self, X, y, score_type)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m#         mlflow.sklearn.log_model(lr, \"model\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m               \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meachModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m               \u001b[0mmodelpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C://mlops_plugin//models//model-%s%f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m               \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#               flow.sklearn.log_model(model,\"model\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "%time ModelObject.runBaseLineModel(x_train,y_train,score_type='test',top_feature=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "urlparse(mlflow.get_tracking_uri()).scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mlruns/4/3b5a2c0c86b342a1860ecf5c51f98f5b/artifacts'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_artifact_uri() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"C:\\mlops_plugin\\src\\models\\pickle_temp\\ModelBaseObject.pickle\",\"wb\")\n",
    "pickle.dump(ModelObject.base_model_output, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"C:\\mlops_plugin\\src\\models\\pickle_temp\\ModelBaseObject_featureimpdf.pickle\",\"wb\")\n",
    "imprtant_feature_df = ModelObject.getFeatureImportance(ModelObject.getFeatureImportanceDF(x_train, ModelObject.feature_importance, ModelObject.important_col))\n",
    "pickle.dump(imprtant_feature_df, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 0.041701126098632815,\n",
       " 'train_accuracy': 0.854417670682731,\n",
       " 'train_precision': 0.8732978864446382,\n",
       " 'train_recall': 0.7216639808672023,\n",
       " 'train_f1_score': 0.7890763028808223,\n",
       " 'train_average_precision': 0.734651796143895,\n",
       " 'train_balanced_accuracy': 0.8283323059309261,\n",
       " 'train_hamming_loss': 0.14558232931726905,\n",
       " 'train_jaccard_score': 0.6518805260675566,\n",
       " 'train_log_loss': 5.028267792247734,\n",
       " 'train_roc_auc_score': 0.8283323059309261,\n",
       " 'train_zero_one_loss': 72.5,\n",
       " 'test_accuracy': 0.7967289719626167,\n",
       " 'test_precision': 0.8084083219962512,\n",
       " 'test_recall': 0.6560295020712281,\n",
       " 'test_f1_score': 0.7225668369162417,\n",
       " 'test_average_precision': 0.668788002474151,\n",
       " 'test_balanced_accuracy': 0.77334379666102,\n",
       " 'test_hamming_loss': 0.20327102803738314,\n",
       " 'test_jaccard_score': 0.566593994717719,\n",
       " 'test_log_loss': 7.020784147771737,\n",
       " 'test_roc_auc_score': 0.7733437966610202,\n",
       " 'test_zero_one_loss': 43.5}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelObject.base_model_output['BaggingClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModellingHelper' object has no attribute 'basemodel_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-d9bf732d365a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mModelObject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemodel_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaseModellingHelper' object has no attribute 'basemodel_scores'"
     ]
    }
   ],
   "source": [
    "ModelObject.basemodel_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
